<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Open Thesis Topics | Hannah Dröge</title> <meta name="author" content="Hannah Dröge"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/eye.png?7ff8b7c708ec0354c4dde984fb8464b4"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://drghannah.github.io/students/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?6185d15ea1982787ad7f435576553d64"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Hannah </span>Dröge</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Open Thesis Topics</h1> <p class="post-description"></p> </header> <article> <p>If you are interested in any of the topics below or have an idea of your own, please feel free to send an e-mail to <a href="mailto:droege@cs.uni-bonn.de">droege@cs.uni-bonn.de</a>.</p> <hr> <h2 id="3d-animal-reconstruction"><strong>3D Animal Reconstruction</strong></h2> <h3 id="gaussian-splatting-for-realistic-fur-textures">Gaussian Splatting for Realistic Fur Textures</h3> <p>This thesis project focuses on creating more visually realistic 3D animal models by improving existing reconstruction techniques. While models like <a href="https://ivenwu.com/CASA/" rel="external nofollow noopener" target="_blank">CASA (Category-Agnostic Skeletal Animal Reconstruction, NeurIPS 2022)</a> have made significant progress in generating accurate skeletons and body shapes from 2D images, they lack fine surface details.</p> <p>To address this, this thesis explores the use of Gaussian splatting to simulate intricate textures, such as fur, on CASA-generated meshes. The primary objectives include developing and optimizing a Gaussian splatting method for fur textures to improve the appearance of 3D animal models. Furthermore, there are also options for extending the system to include animations and/or capturing videos.</p> <hr> <h2 id="deep-image-matting"><strong>Deep Image Matting</strong></h2> <h3 id="real-time-matting-improving-accuracy-with-infrared-data">Real-Time Matting: Improving Accuracy with Infrared Data</h3> <p>Real-time deep image matting is an important first step for many real-time reconstruction methods and an important part of the pipeline in the Capture-Dome. The objective is to improve real-time matting accuracy by incorporating additional infrared (IR) image data.</p> <p>This approach builds on <a href="https://grail.cs.washington.edu/projects/background-matting-v2/" rel="external nofollow noopener" target="_blank">Real-Time High-Resolution Background Matting</a> by encoding IR information alongside color data in the base structure of the matting network. This extra layer of IR data provides detail that color data alone can’t capture, resulting in a much cleaner separation of foreground and background. To make this possible, we’ll use the Mitsuba Renderer to simulate IR and color data, creating a realistic training dataset for the network.</p> <p><img src="/assets/img/IR.png" alt="Alt text" style="width: 85%; height: auto;"></p> <p><em>Camera Rig with two IR-Cameras (left, right), RGB-Camera (center left), and projector (center right).</em></p> <hr> <h3 id="cross-attention-for-improved-background-integration">Cross-Attention for Improved Background Integration</h3> <p>In contrast to real-time deep image matting, which prioritizes speed, offline methods focus on achieving the highest possible quality. In a capture-dome setup, where background matting benefits from capturing an additional empty scene, a robust solution is crucial for offline reconstruction approaches.</p> <p>In this thesis the objective is to extend <a href="https://github.com/hustvl/ViTMatte" rel="external nofollow noopener" target="_blank">Vision Transformer (ViT)-based matting</a> by replacing the traditional trimap input with a background image. Through the introduction of cross-attention between foreground and background embeddings, this approach aims to deliver more precise, context-aware matting. The key objectives include designing an effective cross-attention mechanism and achieving state-of-the-art performance in background replacement.</p> <hr> <h2 id="3d-pose-estimation"><strong>3D Pose Estimation</strong></h2> <h3 id="multi-view-landmark-detection">Multi View Landmark Detection</h3> <p>In this thesis, we aim to integrate the <a href="https://ai.google.dev/edge/mediapipe/solutions/vision/pose_landmarker" rel="external nofollow noopener" target="_blank">MediaPipe Pose Landmarker</a> into the Capture-Dome software for multiview 3D pose estimation. By utilizing MediaPipe’s robust 2D landmark detection across multiple synchronized camera views, the goal is to reconstruct accurate 3D poses. <img src="/assets/img/landmark.png" alt="Alt text" style="width: 85%; height: auto;"></p> <p><em>Landmarks created via MediaPipe Pose Landmarker</em></p> <hr> <h2 id="3d-shape-reconstruction"><strong>3D Shape Reconstruction</strong></h2> <h3 id="neural-radiance-fields-nerf-with-infrared-images">Neural Radiance Fields (NeRF) with Infrared Images</h3> <p>Neural Radiance Fields (NeRF) (e.g. <a href="https://github.com/NVlabs/instant-ngp" rel="external nofollow noopener" target="_blank">InstantNGP</a>) have revolutionized 3D reconstruction by synthesizing high-quality novel views from 2D images. However, NeRF struggles with precise shape reconstruction, especially in challenging lighting conditions or textureless regions.</p> <p>This thesis investigates the integration of infrared (IR) stereo images with active illumination to improve the accuracy of NeRF. The approach utilizes IR stereo cameras with projected patterns to provide additional geometric cues missing from standard RGB inputs.</p> <hr> <h2 id="image-processing"><strong>Image Processing</strong></h2> <h3 id="joint-debayering-and-denoising">Joint Debayering and Denoising</h3> <p>This project explores a joint approach to debayering and denoising to improve image quality, targeting our capture stage data. Possible extensions include leveraging temporal consistency across frames to enhance detail preservation and noise reduction.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Hannah Dröge. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?9b43d6e67ddc7c0855b1478ee4c48c2d" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>